---
title: "R for Big Data"
author: "Colin Gillespie and Robin Lovelace"
output: 
  pdf_document: 
    number_sections: yes
---

# Introduction

## What is 'Big Data'?

## Why R for Big Data?

## Why not R for Big Data?

## Alternatives to R

# Memory matters

This chapter is about maximising the efficiency of R code by optimising its
use of memory.

# Preprocessing

Here the plan is to discuss things you can do to your data *before* loading
it into R.

# Loading Big Data I: static files

```{r}
# (e.g. via dplyr and RODBC - maybe something like the new and superfast MonetDB)
```

## Text files

Data stored as text files are files that are human-readable when displayed
in a 'plain text' editor such as Microsoft Notepad, Vim or RStudio.
Plain text files are the basis of computing.^[Most
programs can be represented as large collections of scripts written in
plain text. RStudio,
for example, is written in 100s of lines of plain text files, all of which
can be viewed on-line
(see [github.com/rstudio/rstudio](https://github.com/rstudio/rstudio)).
This tutorial was written as a UTF-8 encoded plain text '.Rmd' file.
] 
The advantages of plain text files are:

- Simplicity: quick and easy to understand their contents
- Compatibility: text files work with most software packages
- Portability: text files are quick and easy to load, save and share

The disadvantages of plain text files for Big Data are that they can become
unwieldy, even when compressed (remember the 5.6 Gb file from the introduction),
and their ease of modification: text files are certainly not a highly secure
data format.

The most common format of text file is the trusty .csv file, in which
each column is separated by a comma.

```{r}
write.csv(x = cars[1:3,]) # write a .csv file to the screen
```

Note that in the result from the above operation text strings such as
`"speed"` are enclosed in quote markes wheras raw numbers are not.

> **Challenge**: Save a .csv file of the full 'cars' dataset and open it with a plain text editor.

## Files from proprietary formats

# Loading data II: from databases



## Data from an SQL database

## MonetDB

## Comparing load times using different approaches

# Manipulating large datasets with R

Rarely are datasets provided in a form that is analysis-ready.
Usually, datasets must be manipulated, 'wrangled' or
'munged' into a format that is suitable for performing the
analysis that you want to do.

## Data manipulation with **dplyr**

## The **data.table** approach

## Revolution R

```{r}
# TODO: more methods for data manipulation
```

# Big Data visualisation

```{r}
# TODO (RL): Add analogy to refining to reduce volume
```

# Using C++ for 'heavy lifting' 

```{r, echo=FALSE}
# Additional potential topics
# Running R 'in the cloud'
```


